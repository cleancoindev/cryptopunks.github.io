---
layout: post
title:  "Создаём статику для старых, уязвимых и неподдерживаемых более CMS"
meta_description: "Многие самописные и неподдерживаемые более CMS представляют угрозу для сайта. Разберём как с этим быть."
date:   2019-04-20
tags: html static cms security wordpress joomla git github
categories: article
author: "soko1"
---

В интернете существует огромное кол-во сайтов на старых и более не поддерживаемых CMS. Обычно это самописные, или просто более не развиваемые CMS, либо это могут быть наборы плагинов, которые перестали развиваться.

Обычно в таких местах огромное кол-во ошибок, sql-инъекций и других лазеек, которые не упускают взломщики с целью воспользоваться ресурсами взломанного сайта. <br>

В итоге либо с сайта уводят ваш трафик, либо внедряют опасный код и домен в итоге попадает в бан-лист google/mozilla из которого довольно сложно потом выбраться.

Поскольку поддерживать всё в актуальном состоянии иногда не представляется возможным в том числе мне, то пришлось придумать следующий хак — статика.

Алгоритм примерно такой: 

* разворачиваем на локалхосте уязвимый и старый сайт (например, в docker)
* прописываем в **/etc/hosts** домен с локальным айпи
* используем wget для скачивания статики
* заливаем статический сайт на любой хостинг (даже без СУБД, php и прочего)
* при необходимости меняем что необходимо на локалхосте и повторяем процедуру с перезаливкой сгенерированных статических страниц на сайт


## Обо всём подробнее

Если сайт больше не поддерживается и обновлять на нём информацию нет необходимости — первые два пункта можно пропустить и сразу приступить к третьему.

На первом пункте я не буду акцентировать внимание. Не важно где будет находится CMS с сайтом, важно чтобы к ней не имел доступ никто извне. Мне самым удобным кажется docker. Разворачиваем контейнер c каким нибудь LAMP, заливаем туда скрипты с сайтом, импортируем базу, запускаем.

Далее в **/etc/hosts** прописываем домен с сайтом:

```
127.0.0.1 	cryptopunks.org
```

Используем wget для генерации HTML со всеми необходимыми стилями, JS, картиками и другим контентом:

```
$ wget -r -l 7 -p -nc http://cryptopunks.org
```

Далее заливаем все файлы на хостинг вместо дырявых скриптов.

Я предлагаю использовать для этого Github Pages.

Плюсов у Github Pages перед другими хостингами несколько:

* бесплатно, а значит и не отключат за неуплату
* не нужно будет обслуживать никак сервер
* сайт не будет подвержен DDOS-атакам
* будет выдан бесплатный https-сертификат
* будет доступна история всех изменений
* если вдруг вы потеряете контроль над доменом — всегда будет резервный вариант работы с сайтом через *имясайта.github.io*
* если с вами что-то случится — сайт останется и его смогу склонировать себе другие

Итак, для того чтобы создать страницу с сайтом — регистрируемся на github, создаём новую организацию (например, **cryptopunks**), далее создаём репозиторий с именем **cryptopunks.github.io** (именно в таком формате: **название_организации** + **github.io**) и заливаем туда сайт. Создаём в репозитории файлик **CNAME** с названием вашего домена (например, **cryptopunks.org**), в DNS домена прописываем IP который выдаётся при:

```
$ ping cryptopunks.github.io
```

Если домена нет — используем адрес https://cryptopunks.github.io

В настройках репозитория не забываем включить HTTPS. 

Всё, теперь ваш сайт безопасен, автономен и не требует какого-либо обслуживания. 

## Ну и напоследок

Естественно необходимо учитывать, что в статическом сайте может работать далеко не всё что работало у вас в случае с динамическим. Например, по понятным причинам скорее всего не будет работать поиск, авторизация и прочие плюшки, требующие взаимодействия с сервером. Поэтому это всё надо либо предварительно отключить, либо огранизовать функционал на JS.

Кроме того, полезным будет пройтись каким нибудь сервисом вроде [этого](https://www.brokenlinkcheck.com/) чтобы проверить не появилось ли на вашем сайте битых ссылок. И убедиться что старые адреса соответствуют новым, иначе можно потерять вес в поисковиковых системах. 

Ещё можно предусмотреть страницу **404.html**, т.к. wget её скорее всего не создаст. Ну и карту сайта **sitemap.xml**.